{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6948138d-380c-4586-fc2c-0cfed7011144"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Get the GPU\n",
        "if torch.cuda.is_available():        \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdae031-7a51-42bd-a0b3-1e1a638db646"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 26.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 19.8MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 16.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 13.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 13.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 12.7MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 11.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 11.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 11.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 11.0MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 11.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163kB 11.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 11.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a77a3f7cfe12604d22c836433cb4c2c4e19cb6da69a44badd73514237f388c02\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdWf7hQlt2OI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ceb7e05-5628-4c6e-da19-9d0c9343783f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th1nMaH6uPom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8bc1b3b-bdee-43f4-e241-880a6a549c42"
      },
      "source": [
        "import zipfile\n",
        "!unzip /content/drive/\"My Drive\"/\"Colab Notebooks\"/sample.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/sample.zip\n",
            "  inflating: sample100k.csv          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "7f44542f-f5a0-405c-fc0d-9816458cbac0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"sample100k.csv\")\n",
        "\n",
        "print(df.shape[0])\n",
        "df['label'] = (df['label'] == 2).astype('int')\n",
        "df = df[pd.notnull(df['title'])]\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>body</th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5761</th>\n",
              "      <td>253455</td>\n",
              "      <td>Carter Page insists he was never worried about...</td>\n",
              "      <td>Carter Page Insists He Was Never Worried About...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24226</th>\n",
              "      <td>177107</td>\n",
              "      <td>As with all WorldTour races, each of the 18 te...</td>\n",
              "      <td>Liege-Bastogne-Liege 2019 provisional startlis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29674</th>\n",
              "      <td>134982</td>\n",
              "      <td>France’s new health ministry committee has met...</td>\n",
              "      <td>Babies in rural regions of France keep being b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49594</th>\n",
              "      <td>143209</td>\n",
              "      <td>France’s yellow vests, coming together in info...</td>\n",
              "      <td>Forgotten France Rises Up</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6048</th>\n",
              "      <td>212509</td>\n",
              "      <td>Embattled Hollywood producer Harvey Weinstein ...</td>\n",
              "      <td>Harvey Weinstein faces new legal battle over '...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46571</th>\n",
              "      <td>52772</td>\n",
              "      <td>A conman bankrolled his son’s £44,000 bar mitz...</td>\n",
              "      <td>Conman used £100,000 jewels scam to pay for so...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53262</th>\n",
              "      <td>279290</td>\n",
              "      <td>Maryland's Republican Gov. Larry Hogan says th...</td>\n",
              "      <td>Larry Hogan: Trump looks \"pretty weak\" for 202...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45674</th>\n",
              "      <td>4100</td>\n",
              "      <td>Sen. Elizabeth Warren, D-Mass., suggested on S...</td>\n",
              "      <td>Warren compares herself, ‘green manufacturing ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21045</th>\n",
              "      <td>240956</td>\n",
              "      <td>Ivanka Trump was accused on Thursday of violat...</td>\n",
              "      <td>Booker denounces Biden's refusal to apologize ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29356</th>\n",
              "      <td>233400</td>\n",
              "      <td>Two weeks ago I was on an easyJet flight from ...</td>\n",
              "      <td>Want to arrive on time? You&amp;apos;ll need to pa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ... label\n",
              "5761       253455  ...     1\n",
              "24226      177107  ...     0\n",
              "29674      134982  ...     0\n",
              "49594      143209  ...     1\n",
              "6048       212509  ...     0\n",
              "46571       52772  ...     0\n",
              "53262      279290  ...     0\n",
              "45674        4100  ...     1\n",
              "21045      240956  ...     0\n",
              "29356      233400  ...     0\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.title.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f763ab83-7a45-4af1-850f-04df19676806"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c48c72-fe28-43eb-9ff2-d0c0fa8ca644"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 24,           # Pad & truncate all sentences.\n",
        "                        padding = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Kamala Harris calls on Jerry Nadler to get the ball rolling on Kavanaugh impeachment\n",
            "Token IDs: tensor([  101, 21911,  2050,  5671,  4455,  2006,  6128, 23233,  3917,  2000,\n",
            "         2131,  1996,  3608,  5291,  2006, 10556, 27313,  8953, 17727,  5243,\n",
            "        22729,   102,     0,     0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e4c26a-3edc-4938-886c-6a4651566bcb"
      },
      "source": [
        "# train:test:validation = 82:9:9\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 91-9 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.91 * len(dataset))\n",
        "val_size = (len(dataset) - train_size)\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "train_size = int(0.91 * len(train_dataset))\n",
        "test_size = (len(train_dataset) - train_size)\n",
        "train_dataset, test_dataset = random_split(train_dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} validation samples'.format(test_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82,809 training samples\n",
            "9,000 validation samples\n",
            "8,190 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset, \n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb495fd-3dc1-46e3-ef74-b0c167e34c3b"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.l\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bc6ad4-cb63-4be3-fef6-763afbb82591"
      },
      "source": [
        "# # Get all of the model's parameters as a list of tuples.\n",
        "# params = list(model.named_parameters())\n",
        "\n",
        "# print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "# print('==== Embedding Layer ====\\n')\n",
        "\n",
        "# for p in params[0:5]:\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "# print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "# for p in params[5:21]:\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "# print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "# for p in params[-4:]:\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e330ab85-c881-479b-d73a-a682341d1b9b"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print('Epoch {:} / {:}'.format(epoch_i + 1, epochs))\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "         \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        \n",
        "        model.zero_grad()        \n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    \n",
        "    print(\"\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  2,588.    Elapsed: 0:00:07.\n",
            "  Batch    80  of  2,588.    Elapsed: 0:00:14.\n",
            "  Batch   120  of  2,588.    Elapsed: 0:00:22.\n",
            "  Batch   160  of  2,588.    Elapsed: 0:00:29.\n",
            "  Batch   200  of  2,588.    Elapsed: 0:00:36.\n",
            "  Batch   240  of  2,588.    Elapsed: 0:00:42.\n",
            "  Batch   280  of  2,588.    Elapsed: 0:00:49.\n",
            "  Batch   320  of  2,588.    Elapsed: 0:00:56.\n",
            "  Batch   360  of  2,588.    Elapsed: 0:01:03.\n",
            "  Batch   400  of  2,588.    Elapsed: 0:01:10.\n",
            "  Batch   440  of  2,588.    Elapsed: 0:01:16.\n",
            "  Batch   480  of  2,588.    Elapsed: 0:01:23.\n",
            "  Batch   520  of  2,588.    Elapsed: 0:01:30.\n",
            "  Batch   560  of  2,588.    Elapsed: 0:01:37.\n",
            "  Batch   600  of  2,588.    Elapsed: 0:01:44.\n",
            "  Batch   640  of  2,588.    Elapsed: 0:01:51.\n",
            "  Batch   680  of  2,588.    Elapsed: 0:01:58.\n",
            "  Batch   720  of  2,588.    Elapsed: 0:02:05.\n",
            "  Batch   760  of  2,588.    Elapsed: 0:02:12.\n",
            "  Batch   800  of  2,588.    Elapsed: 0:02:19.\n",
            "  Batch   840  of  2,588.    Elapsed: 0:02:25.\n",
            "  Batch   880  of  2,588.    Elapsed: 0:02:32.\n",
            "  Batch   920  of  2,588.    Elapsed: 0:02:39.\n",
            "  Batch   960  of  2,588.    Elapsed: 0:02:46.\n",
            "  Batch 1,000  of  2,588.    Elapsed: 0:02:53.\n",
            "  Batch 1,040  of  2,588.    Elapsed: 0:03:00.\n",
            "  Batch 1,080  of  2,588.    Elapsed: 0:03:07.\n",
            "  Batch 1,120  of  2,588.    Elapsed: 0:03:13.\n",
            "  Batch 1,160  of  2,588.    Elapsed: 0:03:20.\n",
            "  Batch 1,200  of  2,588.    Elapsed: 0:03:27.\n",
            "  Batch 1,240  of  2,588.    Elapsed: 0:03:34.\n",
            "  Batch 1,280  of  2,588.    Elapsed: 0:03:41.\n",
            "  Batch 1,320  of  2,588.    Elapsed: 0:03:48.\n",
            "  Batch 1,360  of  2,588.    Elapsed: 0:03:55.\n",
            "  Batch 1,400  of  2,588.    Elapsed: 0:04:02.\n",
            "  Batch 1,440  of  2,588.    Elapsed: 0:04:09.\n",
            "  Batch 1,480  of  2,588.    Elapsed: 0:04:15.\n",
            "  Batch 1,520  of  2,588.    Elapsed: 0:04:22.\n",
            "  Batch 1,560  of  2,588.    Elapsed: 0:04:29.\n",
            "  Batch 1,600  of  2,588.    Elapsed: 0:04:36.\n",
            "  Batch 1,640  of  2,588.    Elapsed: 0:04:43.\n",
            "  Batch 1,680  of  2,588.    Elapsed: 0:04:50.\n",
            "  Batch 1,720  of  2,588.    Elapsed: 0:04:57.\n",
            "  Batch 1,760  of  2,588.    Elapsed: 0:05:03.\n",
            "  Batch 1,800  of  2,588.    Elapsed: 0:05:10.\n",
            "  Batch 1,840  of  2,588.    Elapsed: 0:05:17.\n",
            "  Batch 1,880  of  2,588.    Elapsed: 0:05:24.\n",
            "  Batch 1,920  of  2,588.    Elapsed: 0:05:31.\n",
            "  Batch 1,960  of  2,588.    Elapsed: 0:05:38.\n",
            "  Batch 2,000  of  2,588.    Elapsed: 0:05:45.\n",
            "  Batch 2,040  of  2,588.    Elapsed: 0:05:52.\n",
            "  Batch 2,080  of  2,588.    Elapsed: 0:05:58.\n",
            "  Batch 2,120  of  2,588.    Elapsed: 0:06:05.\n",
            "  Batch 2,160  of  2,588.    Elapsed: 0:06:12.\n",
            "  Batch 2,200  of  2,588.    Elapsed: 0:06:19.\n",
            "  Batch 2,240  of  2,588.    Elapsed: 0:06:26.\n",
            "  Batch 2,280  of  2,588.    Elapsed: 0:06:33.\n",
            "  Batch 2,320  of  2,588.    Elapsed: 0:06:40.\n",
            "  Batch 2,360  of  2,588.    Elapsed: 0:06:47.\n",
            "  Batch 2,400  of  2,588.    Elapsed: 0:06:53.\n",
            "  Batch 2,440  of  2,588.    Elapsed: 0:07:00.\n",
            "  Batch 2,480  of  2,588.    Elapsed: 0:07:07.\n",
            "  Batch 2,520  of  2,588.    Elapsed: 0:07:14.\n",
            "  Batch 2,560  of  2,588.    Elapsed: 0:07:21.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:07:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  2,588.    Elapsed: 0:00:07.\n",
            "  Batch    80  of  2,588.    Elapsed: 0:00:14.\n",
            "  Batch   120  of  2,588.    Elapsed: 0:00:21.\n",
            "  Batch   160  of  2,588.    Elapsed: 0:00:28.\n",
            "  Batch   200  of  2,588.    Elapsed: 0:00:34.\n",
            "  Batch   240  of  2,588.    Elapsed: 0:00:41.\n",
            "  Batch   280  of  2,588.    Elapsed: 0:00:48.\n",
            "  Batch   320  of  2,588.    Elapsed: 0:00:55.\n",
            "  Batch   360  of  2,588.    Elapsed: 0:01:02.\n",
            "  Batch   400  of  2,588.    Elapsed: 0:01:09.\n",
            "  Batch   440  of  2,588.    Elapsed: 0:01:16.\n",
            "  Batch   480  of  2,588.    Elapsed: 0:01:23.\n",
            "  Batch   520  of  2,588.    Elapsed: 0:01:29.\n",
            "  Batch   560  of  2,588.    Elapsed: 0:01:36.\n",
            "  Batch   600  of  2,588.    Elapsed: 0:01:43.\n",
            "  Batch   640  of  2,588.    Elapsed: 0:01:50.\n",
            "  Batch   680  of  2,588.    Elapsed: 0:01:57.\n",
            "  Batch   720  of  2,588.    Elapsed: 0:02:04.\n",
            "  Batch   760  of  2,588.    Elapsed: 0:02:11.\n",
            "  Batch   800  of  2,588.    Elapsed: 0:02:18.\n",
            "  Batch   840  of  2,588.    Elapsed: 0:02:24.\n",
            "  Batch   880  of  2,588.    Elapsed: 0:02:31.\n",
            "  Batch   920  of  2,588.    Elapsed: 0:02:38.\n",
            "  Batch   960  of  2,588.    Elapsed: 0:02:45.\n",
            "  Batch 1,000  of  2,588.    Elapsed: 0:02:52.\n",
            "  Batch 1,040  of  2,588.    Elapsed: 0:02:59.\n",
            "  Batch 1,080  of  2,588.    Elapsed: 0:03:06.\n",
            "  Batch 1,120  of  2,588.    Elapsed: 0:03:13.\n",
            "  Batch 1,160  of  2,588.    Elapsed: 0:03:19.\n",
            "  Batch 1,200  of  2,588.    Elapsed: 0:03:26.\n",
            "  Batch 1,240  of  2,588.    Elapsed: 0:03:33.\n",
            "  Batch 1,280  of  2,588.    Elapsed: 0:03:40.\n",
            "  Batch 1,320  of  2,588.    Elapsed: 0:03:47.\n",
            "  Batch 1,360  of  2,588.    Elapsed: 0:03:54.\n",
            "  Batch 1,400  of  2,588.    Elapsed: 0:04:01.\n",
            "  Batch 1,440  of  2,588.    Elapsed: 0:04:07.\n",
            "  Batch 1,480  of  2,588.    Elapsed: 0:04:14.\n",
            "  Batch 1,520  of  2,588.    Elapsed: 0:04:21.\n",
            "  Batch 1,560  of  2,588.    Elapsed: 0:04:28.\n",
            "  Batch 1,600  of  2,588.    Elapsed: 0:04:35.\n",
            "  Batch 1,640  of  2,588.    Elapsed: 0:04:42.\n",
            "  Batch 1,680  of  2,588.    Elapsed: 0:04:49.\n",
            "  Batch 1,720  of  2,588.    Elapsed: 0:04:56.\n",
            "  Batch 1,760  of  2,588.    Elapsed: 0:05:02.\n",
            "  Batch 1,800  of  2,588.    Elapsed: 0:05:09.\n",
            "  Batch 1,840  of  2,588.    Elapsed: 0:05:16.\n",
            "  Batch 1,880  of  2,588.    Elapsed: 0:05:23.\n",
            "  Batch 1,920  of  2,588.    Elapsed: 0:05:30.\n",
            "  Batch 1,960  of  2,588.    Elapsed: 0:05:37.\n",
            "  Batch 2,000  of  2,588.    Elapsed: 0:05:44.\n",
            "  Batch 2,040  of  2,588.    Elapsed: 0:05:51.\n",
            "  Batch 2,080  of  2,588.    Elapsed: 0:05:57.\n",
            "  Batch 2,120  of  2,588.    Elapsed: 0:06:04.\n",
            "  Batch 2,160  of  2,588.    Elapsed: 0:06:11.\n",
            "  Batch 2,200  of  2,588.    Elapsed: 0:06:18.\n",
            "  Batch 2,240  of  2,588.    Elapsed: 0:06:25.\n",
            "  Batch 2,280  of  2,588.    Elapsed: 0:06:32.\n",
            "  Batch 2,320  of  2,588.    Elapsed: 0:06:39.\n",
            "  Batch 2,360  of  2,588.    Elapsed: 0:06:46.\n",
            "  Batch 2,400  of  2,588.    Elapsed: 0:06:52.\n",
            "  Batch 2,440  of  2,588.    Elapsed: 0:06:59.\n",
            "  Batch 2,480  of  2,588.    Elapsed: 0:07:06.\n",
            "  Batch 2,520  of  2,588.    Elapsed: 0:07:13.\n",
            "  Batch 2,560  of  2,588.    Elapsed: 0:07:20.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:07:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:15:19 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "f73a2808-9537-453a-fc51-f2f9f130a25a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:07:26</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:07:25</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.39         0.33           0.85       0:07:26         0:00:14\n",
              "2               0.25         0.33           0.86       0:07:25         0:00:14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "450f7e33-27bb-4e4e-e6ff-0120cc87b3b5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqBPhlrLuarT"
      },
      "source": [
        "prediction_data = test_dataset\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467407ef-c32e-47f9-94e0-2193e7ec3a61"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 99,999 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d891a51-27ee-41a1-f8ff-9bc32de4647f"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 30000 of 99999 (30.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3883937a-86a2-46b3-94cc-d6be6aa50a9b"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht040uaBE1dZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "9e5af377-052b-495f-bdf6-2cf124f19e12"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        print(j,i,cm[i,j])\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "from sklearn import metrics\n",
        "cm = metrics.confusion_matrix(flat_true_labels, flat_predictions)\n",
        "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])\n",
        "print(accuracy_score(flat_true_labels, flat_predictions))\n",
        "print(f1_score(flat_true_labels, flat_predictions,average='macro'))\n",
        "print(f1_score(flat_true_labels, flat_predictions,average='weighted'))\n",
        "print(f1_score(flat_true_labels, flat_predictions,average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "0 0 5303\n",
            "1 0 477\n",
            "0 1 674\n",
            "1 1 1736\n",
            "0.8594627594627595\n",
            "0.8265641737063929\n",
            "0.8576458204680848\n",
            "0.8594627594627595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "## A1. Saving & Loading Fine-Tuned Model\n",
        "\n",
        "This first cell (taken from `run_glue.py` [here](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) writes the model and tokenizer out to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a5517081-2e05-4244-c8df-77a9558ff75a"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-tjHkR7lc1I"
      },
      "source": [
        "Let's check out the file sizes, out of curiosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "6df0b283-6458-4d95-8455-2e7537193d1b"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427960K\n",
            "-rw-r--r-- 1 root root      2K Mar 18 15:53 config.json\n",
            "-rw-r--r-- 1 root root 427719K Mar 18 15:53 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Mar 18 15:53 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Mar 18 15:53 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Mar 18 15:53 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr_bt2rFlgDn"
      },
      "source": [
        "The largest file is the model weights, at around 418 megabytes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70780762-7790-474f-e5c2-304a066945ae"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 418M Mar 18 15:53 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzGKvOFAll_e"
      },
      "source": [
        "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trr-A-POC18_"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./drive/Shared drives/ChrisMcCormick.AI/Blog Posts/BERT Fine-Tuning/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vstijw85SZ"
      },
      "source": [
        "The following functions will load the model back from disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nskPzUM084zL"
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = model_class.from_pretrained(output_dir)\n",
        "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}